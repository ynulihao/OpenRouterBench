# LLMRouterBench Baseline Data Loading Configuration
#
# This configuration controls how benchmark results are loaded and transformed
# into baseline format for analysis and comparison.

baseline:
  # Data Source
  # -----------
  # Directory containing benchmark result files
  results_dir: "results/bench"

  # Data Filtering
  # --------------
  # Control which results to include in the baseline dataset
  #
  # Priority: Include lists (whitelist) > Exclude lists (blacklist)
  # - If 'datasets' is set (not null), only those datasets are loaded
  # - If 'datasets' is null and 'exclude_datasets' is set, all datasets except those are loaded
  # - Same logic applies to 'models' and 'splits'
  filters:
    # Skip demo/test results (recommended: true)
    skip_demo: true

    # Include lists (whitelist) - higher priority
    # If set (not null), only these items are loaded, and exclude lists are ignored

    # Filter by specific datasets (null = include all)
    # Example: ['aime', 'humaneval', 'bbh']
    datasets: ['aime', 'bbh', 'emorynlp', 'finqa', 'gpqa', 'humaneval', 'kandk', 'korbench', 'livecodebench', 'math500', 'mathbench', 'mbpp', 'medqa', 'meld', 'mmlupro'] # arcc, livemathbench, winogrande

    # Filter by specific models (null = include all)
    # Example: ['gpt-4', 'claude-3', 'gemini-pro']
    models: ["cogito-v1-preview-llama-8B", "DeepHermes-3-Llama-3-8B-Preview", "DeepSeek-R1-0528-Qwen3-8B", "DeepSeek-R1-Distill-Qwen-7B", "Fin-R1", "gemma-2-9b-it", "glm-4-9b-chat", "GLM-Z1-9B-0414", "granite-3.3-8b-instruct", "Intern-S1-mini", "internlm3-8b-instruct", "Llama-3.1-8B-Instruct", "Llama-3.1-8B-UltraMedical", "Llama-3.1-Nemotron-Nano-8B-v1", "MiMo-7B-RL-0530", "MiniCPM4.1-8B", "NVIDIA-Nemotron-Nano-9B-v2", "OpenThinker3-7B", "Qwen3-8B", "Qwen2.5-Coder-7B-Instruct"]

    # Filter by specific splits (null = include all)
    # Example: ['test', 'valid']
    splits: null

    # Exclude lists (blacklist) - only effective when include list is null
    # If the corresponding include list is null, these items will be excluded

    # Exclude specific datasets (null = no exclusions)
    # Example: ['test_dataset', 'debug_dataset']
    exclude_datasets: null

    # Exclude specific models (null = no exclusions)
    # Example: ['failed-model', 'incomplete-model']
    exclude_models: null

    # Exclude specific splits (null = no exclusions)
    # Example: ['debug']
    exclude_splits: null

  # Column Selection
  # ----------------
  # Explicitly specify which columns to include in the output
  # This reduces memory usage and file size by only loading needed fields
  #
  # Available columns:
  #   - dataset_id, split, model_name, record_index (identification)
  #   - origin_query, prompt (input)
  #   - prediction, raw_output (output)
  #   - ground_truth, score (evaluation)
  #   - prompt_tokens, completion_tokens, cost (resources)
  columns:
    include:
      - dataset_id
      - split
      - model_name
      - record_index
      - prompt
      - score
      - cost
